{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling & predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import uniform, randint\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_predict, cross_val_score, KFold\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Lasso, LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "#from sklearn.utils import resample\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_train = pd.read_csv('data/preprocessed_training_data.csv')\n",
    "\n",
    "prep_X_train = pd.read_csv('data/preprocessed_X_train.csv')\n",
    "prep_X_train_scaled = pd.read_csv('data/preprocessed_X_train_scaled.csv')\n",
    "\n",
    "prep_y_train = pd.read_csv('data/preprocessed_y_train.csv')\n",
    "\n",
    "orig_X_test = pd.read_csv('data/test.csv')\n",
    "prep_X_test = pd.read_csv('data/preprocessed_X_test.csv')\n",
    "prep_X_test_scaled = pd.read_csv('data/preprocessed_X_test_scaled.csv')\n",
    "\n",
    "orig_X_test2 = pd.read_csv('data/test_2.csv')\n",
    "test_modified_3 = pd.read_csv('data/preprocessed_X_test2.csv')\n",
    "prep_X_test2_scaled = pd.read_csv('data/preprocessed_X_test2_scaled.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ways to enhance prediction accuracy\n",
    "- Feature scaling (StandardScaler)\n",
    "- Tuning of hyperparameters\n",
    "- Cross-validation\n",
    "- Removal of outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_scale_training_data(X, y, test_size=0.2, random_state=42):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled, y_train, y_test\n",
    "\n",
    "\n",
    "def save_predictions_to_csv(predictions):\n",
    "    results = pd.DataFrame()\n",
    "    results['Id'] = orig_X_test['Id']\n",
    "    results['target'] = predictions\n",
    "    results.to_csv('data/results.csv', index=False)\n",
    "    return results\n",
    "\n",
    "\n",
    "def define_X_y_split_and_scale_training_data(data, test_size=0.2, random_state=42):\n",
    "    X = data.drop('pSat_Pa', axis=1)\n",
    "    y = data.copy()[['pSat_Pa']]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled, y_train, y_test\n",
    "\n",
    "\n",
    "def split_train_data_and_scale_after_feature_engineering(train_data, test_data):\n",
    "    X_train = train_data.drop('pSat_Pa', axis=1)\n",
    "    y_train = train_data.copy()[['pSat_Pa']]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(test_data)\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled, y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate R2 values on training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare basic versions of different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_basic_versions_of_models(X, y, test_size=0.2, random_state=42, use_scaler=True):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    if use_scaler:\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "    \n",
    "    regressors = {\n",
    "        'Dummy Model': DummyRegressor(),\n",
    "        'OLS Linear Regression': LinearRegression(),\n",
    "        'Random Forest': RandomForestRegressor(random_state=random_state),\n",
    "        'SVR': SVR(),\n",
    "        'Lasso': Lasso(random_state=random_state),\n",
    "        'XGBRegressor': xgb.XGBRegressor(),\n",
    "    }\n",
    "\n",
    "    for name, regressor in regressors.items():\n",
    "        model = regressor.fit(X_train, y_train.values.ravel())\n",
    "        predictions = model.predict(X_test)\n",
    "        r2 = r2_score(y_test, predictions)\n",
    "        print(f'{name}: R^2 Score = {r2:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without standard scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Model: R^2 Score = -0.0000\n",
      "OLS Linear Regression: R^2 Score = 0.6957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: R^2 Score = 0.7105\n",
      "SVR: R^2 Score = 0.4713\n",
      "Lasso: R^2 Score = 0.3295\n"
     ]
    }
   ],
   "source": [
    "test_basic_versions_of_models(X=prep_X_train, y=prep_y_train, test_size=0.2, random_state=42, use_scaler=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With standard scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Model: R^2 Score = -0.0000\n",
      "OLS Linear Regression: R^2 Score = 0.6944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: R^2 Score = 0.7106\n",
      "SVR: R^2 Score = 0.7383\n",
      "Lasso: R^2 Score = 0.2664\n"
     ]
    }
   ],
   "source": [
    "test_basic_versions_of_models(X=prep_X_train, y=prep_y_train, test_size=0.2, random_state=42, use_scaler=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svr_basic(X_train, y_train, X_test):\n",
    "    svr = SVR()\n",
    "    svr.fit(X_train, y_train.values.ravel())\n",
    "    y_pred = svr.predict(X_test)\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.7383008493915951\n"
     ]
    }
   ],
   "source": [
    "X_train_scaled, X_test_scaled, y_train, y_test = split_and_scale_training_data(prep_X_train, prep_y_train)\n",
    "\n",
    "y_pred = svr_basic(X_train_scaled, y_train, X_test_scaled)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict on actual test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svr_basic(prep_X_train_scaled, prep_y_train, prep_X_test_scaled)\n",
    "\n",
    "results = save_predictions_to_csv(y_pred)\n",
    "\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search optimal parameters for SVR using GridSearch (takes a long time!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svr_hyperparameter_grid_search(X_train, y_train, X_test):\n",
    "    param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'epsilon': [0.1, 0.2, 0.5]\n",
    "    }\n",
    "\n",
    "    svr = SVR()\n",
    "    grid_search = GridSearchCV(svr, param_grid, cv=5, scoring='r2')\n",
    "    grid_search.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    best_svr = SVR(**best_params)\n",
    "    best_svr.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "    y_pred = best_svr.predict(X_test)\n",
    "    \n",
    "    return best_params, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled, X_test_scaled, y_train, y_test = split_and_scale_training_data(prep_X_train, prep_y_train)\n",
    "\n",
    "best_params, y_pred = svr_hyperparameter_grid_search(X_train_scaled, y_train, X_test_scaled)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Best parameters:\", best_params)\n",
    "print(\"R2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR with hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svr_with_hyperparameter_tuning(X_train, y_train, X_test):\n",
    "    svr = SVR(C=10, kernel='rbf', gamma='scale', epsilon=0.5) # default C=1, kernel=\"rbf\", gamma=\"scale\", epsilon=0.1\n",
    "    svr.fit(X_train, y_train.values.ravel())\n",
    "    y_pred = svr.predict(X_test)\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.7444331502588883\n"
     ]
    }
   ],
   "source": [
    "X_train_scaled, X_test_scaled, y_train, y_test = split_and_scale_training_data(prep_X_train, prep_y_train)\n",
    "\n",
    "y_pred = svr_with_hyperparameter_tuning(X_train_scaled, y_train, X_test_scaled)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict on actual test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svr_with_hyperparameter_tuning(prep_X_train_scaled, prep_y_train, prep_X_test_scaled)\n",
    "\n",
    "results = save_predictions_to_csv(y_pred)\n",
    "\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBRegressor basic version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgbr_basic(X_train, y_train, X_test):\n",
    "    model = xgb.XGBRegressor()\n",
    "    model.fit(X_train, y_train.values.ravel())\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.7299198444669608\n"
     ]
    }
   ],
   "source": [
    "X_train_scaled, X_test_scaled, y_train, y_test = split_and_scale_training_data(prep_X_train, prep_y_train)\n",
    "\n",
    "y_pred = xgbr_basic(X_train_scaled, y_train, X_test_scaled)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### R2 using cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score CV: 0.7243234475265384\n"
     ]
    }
   ],
   "source": [
    "model = xgb.XGBRegressor()\n",
    "scores = cross_val_score(model, X_train_scaled, y_train, scoring='r2', cv=5)\n",
    "print(\"R2 Score CV:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict on actual test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgbr_basic(prep_X_train_scaled, prep_y_train, prep_X_test_scaled)\n",
    "\n",
    "results = save_predictions_to_csv(y_pred)\n",
    "\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search optimal parameters for XGBRegressor using RandomizedSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgbr_hyperparameter_randomized_search(X_train, y_train, X_test):\n",
    "    param_dist = {\n",
    "        'learning_rate': uniform(0.01, 0.3),\n",
    "        'n_estimators': randint(100, 700),\n",
    "        'max_depth': randint(3, 10),\n",
    "        'min_child_weight': randint(1, 20),\n",
    "        'subsample': uniform(0.5, 0.5),\n",
    "        'colsample_bytree': uniform(0.7, 0.3),\n",
    "        'reg_alpha': uniform(0, 0.5),\n",
    "        'reg_lambda': uniform(0, 0.5),\n",
    "        'gamma': uniform(0, 0.5)\n",
    "    }\n",
    "\n",
    "    xgbr = xgb.XGBRegressor()\n",
    "\n",
    "    print(\"Default Parameters:\", xgbr.get_params())\n",
    "    \n",
    "    random_search = RandomizedSearchCV(\n",
    "        xgbr, param_distributions=param_dist, n_iter=20, cv=5, scoring='r2', random_state=42, n_jobs=-1\n",
    "    )\n",
    "\n",
    "    random_search.fit(X_train, y_train)\n",
    "    best_params = random_search.best_params_\n",
    "    best_model = random_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    print(f\"\\nmodel = xgb.XGBRegressor(\")\n",
    "    for key, value in best_params.items():\n",
    "        print(f\"    {key}={value},\")\n",
    "    print(\")\")\n",
    "    \n",
    "    return best_params, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Parameters: {'objective': 'reg:squarederror', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': None, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': None, 'validate_parameters': None, 'verbosity': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "R2 Score: 0.7387929452076731\n",
      "\n",
      "model = xgb.XGBRegressor(\n",
      "    colsample_bytree=0.9828729111737557,\n",
      "    gamma=0.16160146601037761,\n",
      "    learning_rate=0.16563718652300982,\n",
      "    max_depth=3,\n",
      "    min_child_weight=17,\n",
      "    n_estimators=596,\n",
      "    reg_alpha=0.12695770696717235,\n",
      "    reg_lambda=0.1234380314193006,\n",
      "    subsample=0.8481521364198942,\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "X_train_scaled, X_test_scaled, y_train, y_test = split_and_scale_training_data(prep_X_train, prep_y_train)\n",
    "\n",
    "best_params, y_pred = xgbr_hyperparameter_randomized_search(X_train_scaled, y_train, X_test_scaled)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"\\nR2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBRegressor with hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgbr_with_hyperparameter_tuning(X_train, y_train, X_test):\n",
    "    model = xgb.XGBRegressor(\n",
    "        colsample_bytree=0.9828729111737557,\n",
    "        gamma=0.16160146601037761,\n",
    "        learning_rate=0.16563718652300982,\n",
    "        max_depth=3,\n",
    "        min_child_weight=17,\n",
    "        n_estimators=596,\n",
    "        reg_alpha=0.12695770696717235,\n",
    "        reg_lambda=0.1234380314193006,\n",
    "        subsample=0.8481521364198942,\n",
    "    )\n",
    "    model.fit(X_train, y_train.values.ravel())\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.7387929452076731\n"
     ]
    }
   ],
   "source": [
    "X_train_scaled, X_test_scaled, y_train, y_test = split_and_scale_training_data(prep_X_train, prep_y_train)\n",
    "\n",
    "y_pred = xgbr_with_hyperparameter_tuning(X_train_scaled, y_train, X_test_scaled)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict on actual test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgbr_with_hyperparameter_tuning(prep_X_train_scaled, prep_y_train, prep_X_test_scaled)\n",
    "\n",
    "results = save_predictions_to_csv(y_pred)\n",
    "\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest basic version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_basic(X_train, y_train, X_test):\n",
    "    model = RandomForestRegressor(random_state=42)\n",
    "    model.fit(X_train, y_train.values.ravel())\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.7105715664218221\n"
     ]
    }
   ],
   "source": [
    "X_train_scaled, X_test_scaled, y_train, y_test = split_and_scale_training_data(prep_X_train, prep_y_train)\n",
    "\n",
    "y_pred = random_forest_basic(X_train_scaled, y_train, X_test_scaled)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict on actual test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = random_forest_basic(prep_X_train_scaled, prep_y_train, prep_X_test_scaled)\n",
    "\n",
    "results = save_predictions_to_csv(y_pred)\n",
    "\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search optimal parameters for Random forest using RandomizedSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_hyperparameter_randomized_search(X_train, y_train, X_test):\n",
    "    param_dist = {\n",
    "        'n_estimators': randint(100, 700),\n",
    "        'max_depth': [None] + list(randint(5, 50).rvs(size=5)),\n",
    "        'min_samples_split': randint(2, 20),\n",
    "        'min_samples_leaf': randint(1, 20),\n",
    "        'max_features': ['auto', 'sqrt', 'log2', None, 0.5],\n",
    "        'bootstrap': [True, False]\n",
    "    }\n",
    "\n",
    "    rf_model = RandomForestRegressor()\n",
    "    random_search = RandomizedSearchCV(\n",
    "        rf_model, param_distributions=param_dist, n_iter=10, cv=3, scoring='r2', random_state=42\n",
    "    )\n",
    "    random_search.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "    results = random_search.cv_results_\n",
    "\n",
    "    for i, (params, r2_score) in enumerate(zip(results['params'], results['mean_test_score'])):\n",
    "        print(f\"Iteration {i + 1}: Parameters = {params}, R2 Score = {r2_score:.4f}\")\n",
    "\n",
    "    best_params = random_search.best_params_\n",
    "    best_model = random_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    return best_params, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmsaisa/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "3 fits failed out of a total of 30.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mmsaisa/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/mmsaisa/.local/lib/python3.10/site-packages/sklearn/base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/home/mmsaisa/.local/lib/python3.10/site-packages/sklearn/base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/mmsaisa/.local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/mmsaisa/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [0.65476326 0.69539611 0.65057571 0.581801   0.67423475 0.71349514\n",
      "        nan 0.58802637 0.63658829 0.67597725]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: Parameters = {'bootstrap': True, 'max_depth': 5, 'max_features': 0.5, 'min_samples_leaf': 15, 'min_samples_split': 12, 'n_estimators': 171}, R2 Score = 0.6548\n",
      "Iteration 2: Parameters = {'bootstrap': True, 'max_depth': 41, 'max_features': 'sqrt', 'min_samples_leaf': 19, 'min_samples_split': 12, 'n_estimators': 558}, R2 Score = 0.6954\n",
      "Iteration 3: Parameters = {'bootstrap': False, 'max_depth': 41, 'max_features': None, 'min_samples_leaf': 8, 'min_samples_split': 4, 'n_estimators': 408}, R2 Score = 0.6506\n",
      "Iteration 4: Parameters = {'bootstrap': False, 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 13, 'n_estimators': 413}, R2 Score = 0.5818\n",
      "Iteration 5: Parameters = {'bootstrap': False, 'max_depth': 41, 'max_features': None, 'min_samples_leaf': 17, 'min_samples_split': 11, 'n_estimators': 575}, R2 Score = 0.6742\n",
      "Iteration 6: Parameters = {'bootstrap': False, 'max_depth': 29, 'max_features': 'log2', 'min_samples_leaf': 12, 'min_samples_split': 4, 'n_estimators': 584}, R2 Score = 0.7135\n",
      "Iteration 7: Parameters = {'bootstrap': True, 'max_depth': 41, 'max_features': 'auto', 'min_samples_leaf': 7, 'min_samples_split': 19, 'n_estimators': 487}, R2 Score = nan\n",
      "Iteration 8: Parameters = {'bootstrap': True, 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 9, 'min_samples_split': 3, 'n_estimators': 439}, R2 Score = 0.5880\n",
      "Iteration 9: Parameters = {'bootstrap': False, 'max_depth': 5, 'max_features': None, 'min_samples_leaf': 8, 'min_samples_split': 16, 'n_estimators': 134}, R2 Score = 0.6366\n",
      "Iteration 10: Parameters = {'bootstrap': False, 'max_depth': None, 'max_features': None, 'min_samples_leaf': 18, 'min_samples_split': 9, 'n_estimators': 487}, R2 Score = 0.6760\n",
      "Best parameters: {'bootstrap': False, 'max_depth': 29, 'max_features': 'log2', 'min_samples_leaf': 12, 'min_samples_split': 4, 'n_estimators': 584}\n",
      "R2 Score: 0.7138384137104217\n"
     ]
    }
   ],
   "source": [
    "X_train_scaled, X_test_scaled, y_train, y_test = split_and_scale_training_data(prep_X_train, prep_y_train)\n",
    "\n",
    "best_params, y_pred = random_forest_hyperparameter_randomized_search(X_train_scaled, y_train, X_test_scaled)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Best parameters:\", best_params)\n",
    "print(\"R2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest with hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_with_hyperparameter_tuning(X_train, y_train, X_test):\n",
    "    model = RandomForestRegressor(random_state=42, n_estimators=500)#, max_depth=20)\n",
    "    model.fit(X_train, y_train.values.ravel())\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.7131669123772304\n"
     ]
    }
   ],
   "source": [
    "X_train_scaled, X_test_scaled, y_train, y_test = split_and_scale_training_data(prep_X_train, prep_y_train)\n",
    "\n",
    "y_pred = random_forest_with_hyperparameter_tuning(X_train_scaled, y_train, X_test_scaled)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict on actual test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = random_forest_with_hyperparameter_tuning(prep_X_train_scaled, prep_y_train, prep_X_test_scaled)\n",
    "\n",
    "results = save_predictions_to_csv(y_pred)\n",
    "\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter training data MW > 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27147, 33)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27125, 33)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filter_mw_gt_100(train):\n",
    "    return train[train['MW'] > 100]\n",
    "\n",
    "train_modified_1 = filter_mw_gt_100(prep_train)\n",
    "\n",
    "train_modified_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.7516222396593214\n"
     ]
    }
   ],
   "source": [
    "X_train_scaled, X_test_scaled, y_train, y_test = define_X_y_split_and_scale_training_data(train_modified_1)\n",
    "\n",
    "y_pred = svr_basic(X_train_scaled, y_train, X_test_scaled)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.7405315418031904\n"
     ]
    }
   ],
   "source": [
    "y_pred = xgbr_basic(X_train_scaled, y_train, X_test_scaled)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict on actual test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled, X_test_scaled, y_train = split_train_data_and_scale_after_feature_engineering(train_modified_1, prep_X_test)\n",
    "\n",
    "y_pred = svr_basic(X_train_scaled, y_train, X_test_scaled)\n",
    "\n",
    "results = save_predictions_to_csv(y_pred)\n",
    "\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop non-significant (?) features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_non_significant_features(train, test):\n",
    "    columns_to_drop = [\n",
    "        'C.C.C.O.in.non.aromatic.ring',\n",
    "        'aromatic.hydroxyl',\n",
    "        'category_None',\n",
    "        'category_apin_decane',\n",
    "        'category_apin_decane_toluene',\n",
    "        'category_apin_toluene',\n",
    "        'category_decane_toluene',\n",
    "        'nitroester'\n",
    "    ]\n",
    "\n",
    "    train_modified = train.drop(columns_to_drop, axis=1)\n",
    "    test_modified = test.drop(columns_to_drop, axis=1)\n",
    "    \n",
    "    return train_modified, test_modified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.7529589303538307\n"
     ]
    }
   ],
   "source": [
    "train_modified_2, test_modified_2 = drop_non_significant_features(train_modified_1, prep_X_test)\n",
    "\n",
    "X_train_scaled, X_test_scaled, y_train, y_test = define_X_y_split_and_scale_training_data(train_modified_2)\n",
    "\n",
    "y_pred = svr_basic(X_train_scaled, y_train, X_test_scaled)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.7427340887024483\n"
     ]
    }
   ],
   "source": [
    "y_pred = xgbr_basic(X_train_scaled, y_train, X_test_scaled)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict on actual test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled, X_test_scaled, y_train = split_train_data_and_scale_after_feature_engineering(train_modified_2, test_modified_2)\n",
    "\n",
    "y_pred = svr_basic(X_train_scaled, y_train, X_test_scaled)\n",
    "\n",
    "results = save_predictions_to_csv(y_pred)\n",
    "\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new feature for functional group count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_for_func_group_count(train, test):\n",
    "    functional_groups = ['C.C..non.aromatic.', 'C.C.C.O.in.non.aromatic.ring', 'aldehyde', 'aromatic.hydroxyl',\n",
    "        'carbonylperoxyacid', 'carbonylperoxynitrate', 'carboxylic.acid',\n",
    "        'ester', 'ether..alicyclic.', 'hydroperoxide', 'hydroxyl..alkyl.',\n",
    "        'ketone', 'nitrate', 'nitro', 'nitroester', 'peroxide']\n",
    "\n",
    "    train_modified = train.copy()\n",
    "    train_modified['NumOfGroups'] = train_modified[functional_groups].gt(0).sum(axis=1)\n",
    "\n",
    "    test_modified = test.copy()\n",
    "    test_modified['NumOfGroups'] = test_modified[functional_groups].gt(0).sum(axis=1)\n",
    "\n",
    "    return train_modified, test_modified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.753711166383837\n"
     ]
    }
   ],
   "source": [
    "train_modified_3, test_modified_3 = create_feature_for_func_group_count(train_modified_2, prep_X_test)\n",
    "train_modified_3, test_modified_3 = drop_non_significant_features(train_modified_3, test_modified_3)\n",
    "\n",
    "X_train_scaled, X_test_scaled, y_train, y_test = define_X_y_split_and_scale_training_data(train_modified_3)\n",
    "\n",
    "y_pred = svr_basic(X_train_scaled, y_train, X_test_scaled)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.7452083831447354\n"
     ]
    }
   ],
   "source": [
    "y_pred = xgbr_basic(X_train_scaled, y_train, X_test_scaled)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce nitro & nitrate group weight from MW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_nitro_and_nitrate_weight(train, test):\n",
    "    train_modified = train.copy()\n",
    "    train_modified['MW'] = train_modified['MW'] - train_modified['nitro']*46 - train_modified['nitrate']*62\n",
    "\n",
    "    test_modified = test.copy()\n",
    "    test_modified['MW'] = test_modified['MW'] - test_modified['nitro']*46 - test_modified['nitrate']*62\n",
    "\n",
    "    return train_modified, test_modified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.7538312210452933\n"
     ]
    }
   ],
   "source": [
    "train_modified_4, test_modified_4 = reduce_nitro_and_nitrate_weight(train_modified_3, test_modified_3)\n",
    "\n",
    "X_train_scaled, X_test_scaled, y_train, y_test = define_X_y_split_and_scale_training_data(train_modified_4)\n",
    "\n",
    "y_pred = svr_basic(X_train_scaled, y_train, X_test_scaled)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.7436279157768789\n"
     ]
    }
   ],
   "source": [
    "y_pred = xgbr_basic(X_train_scaled, y_train, X_test_scaled)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R2 Score:\", r2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
